{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data pipe line \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Read train data\n",
    "train = pd.read_csv('train.csv')\n",
    "\n",
    "# Look at the shape of the data\n",
    "print('Train shape:', train.shape)\n",
    "\n",
    "# Look at the head() of the data\n",
    "print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "테스트는 train보다 열이 하나 적어야함(target), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the test data\n",
    "test = pandas.read_csv('test.csv')\n",
    "\n",
    "# Print train and test columns\n",
    "print('Train columns:', train.columns.tolist())\n",
    "print('Test columns:', test.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the sample submission file\n",
    "sample_submission = pandas.read_csv('sample_submission.csv')\n",
    "\n",
    "# Look at the head() of the sample submission\n",
    "print(sample_submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Read the train data\n",
    "train = pd.read_csv('train.csv')\n",
    "\n",
    "# Create a Random Forest object\n",
    "rf = sklearn.RandomForestRegressor()\n",
    "\n",
    "# Train a model\n",
    "rf.fit(X=train[['store', 'item']], y=train['sales'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read test and sample submission data\n",
    "test = pd.read_csv('test.csv')\n",
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "# Show the head() of the sample_submission\n",
    "print(sample_submission.head())\n",
    "\n",
    "# Get predictions for the test set\n",
    "test['sales'] = rf.predict(test[['store', 'item']])\n",
    "\n",
    "# Write test predictions using the sample_submission format\n",
    "test[[\"id\", \"sales\"]].to_csv('kaggle_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Create DMatrix on train data\n",
    "dtrain = xgb.DMatrix(data=train[['store', 'item']],\n",
    "                     label=train['sales'])\n",
    "\n",
    "# Define xgboost parameters\n",
    "params = {'objective': 'reg:linear',\n",
    "          'max_depth': 2,\n",
    "          'silent': 1}\n",
    "\n",
    "# Train xgboost model\n",
    "xg_depth_2 = xgb.train(params=params, dtrain=dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DMatrix on train data\n",
    "dtrain = xgb.DMatrix(data=train[['store', 'item']],\n",
    "                     label=train['sales'])\n",
    "\n",
    "# Define xgboost parameters\n",
    "params = {'objective': 'reg:linear',\n",
    "          'max_depth': 8,\n",
    "          'silent': 1}\n",
    "\n",
    "# Train xgboost model\n",
    "xg_depth_8 = xgb.train(params=params, dtrain=dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DMatrix on train data\n",
    "dtrain = xgb.DMatrix(data=train[['store', 'item']],\n",
    "                     label=train['sales'])\n",
    "\n",
    "# Define xgboost parameters\n",
    "params = {'objective': 'reg:linear',\n",
    "          'max_depth': 15,\n",
    "          'silent': 1}\n",
    "\n",
    "# Train xgboost model\n",
    "xg_depth_15 = xgb.train(params=params, dtrain=dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn에 있는 score 함수 쓰기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "dtrain = xgb.DMatrix(data=train[['store', 'item']])\n",
    "dtest = xgb.DMatrix(data=test[['store', 'item']])\n",
    "\n",
    "# For each of 3 trained models\n",
    "for model in [xg_depth_2, xg_depth_8, xg_depth_15]:\n",
    "    # Make predictions\n",
    "    train_pred = model.predict(dtrain)     \n",
    "    test_pred = model.predict(dtest)          \n",
    "    \n",
    "    # Calculate metrics\n",
    "    mse_train = mean_squared_error(train['sales'], train_pred)                  \n",
    "    mse_test = mean_squared_error(test['sales'], test_pred)\n",
    "    print('MSE Train: {:.3f}. MSE Test: {:.3f}'.format(mse_train, mse_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score 함수 직접 만들기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Import MSE from sklearn\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Define your own MSE function\n",
    "def own_mse(y_true, y_pred):\n",
    "  \t# Raise differences to the power of 2\n",
    "    squares = np.power(y_true - y_pred, 2)\n",
    "    # Find mean over all observations\n",
    "    err = np.mean(squares)\n",
    "    return err\n",
    "\n",
    "print('Sklearn MSE: {:.5f}. '.format(mean_squared_error(y_regression_true, y_regression_pred)))\n",
    "print('Your MSE: {:.5f}. '.format(own_mse(y_regression_true, y_regression_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Import log_loss from sklearn\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# Define your own LogLoss function\n",
    "def own_logloss(y_true, prob_pred):\n",
    "  \t# Find loss for each observation\n",
    "    terms = y_true * np.log(prob_pred) + (1 - y_true) * np.log(1 - prob_pred)\n",
    "    # Find mean over all observations\n",
    "    err = np.mean(terms) \n",
    "    return -err\n",
    "\n",
    "print('Sklearn LogLoss: {:.5f}'.format(log_loss(y_classification_true, y_classification_pred)))\n",
    "print('Your LogLoss: {:.5f}'.format(own_logloss(y_classification_true, y_classification_pred)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
